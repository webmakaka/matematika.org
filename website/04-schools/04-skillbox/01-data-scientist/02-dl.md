---
layout: page
title: Skillbox, Профессия‌ ‌Data‌ ‌Scientist‌ - Deep Learning
description: Skillbox, Профессия‌ ‌Data‌ ‌Scientist‌ - Deep Learning
keywords: Skillbox, Профессия‌ ‌Data‌ ‌Scientist‌, Deep Learning
permalink: /schools/skillbox/data-scientist/dl/
---

# [Skillbox] Профессия‌ ‌Data‌ ‌Scientist‌ - Deep Learning

<br/>
 
Библиотека Keras, TF 1.4 в какой-то момент начинаем работать с версией 2.0

<br/>

01 - 04 Введение

05 - 14 Computer Vision

13 - 15 NLP

16 - 17 Reinforcement Learning

18 - Ускорение и оптимизация

19 - Внедрение моделей в production

<br/>

### 1.2 Линейный классификатор.

<br/>

### 1.4 Функционал ошибки

<br/>

### 1.6 Нейрон и логистическая регрессия

<br/>

### 2.1 Градиентный спуск

<br/>

### 2.3 Метод обратного распространения ошибки

<br/>

### 2.6 Функции активации

<br/>

### 3.5 Определение модели в Tensorflow

<br/>

### 3.7 Обучение модели в Tensorflow

- [линк](https://colab.research.google.com/drive/1dwU04DSiC8A8RWtzpzR2wWByHX_6qJKY)

**Определение лосс функции**

На протяжении курса вы познакомились как минимум с тремя типами функций потерь

- MSE (mean squared error) -- для задачи регрессии
- Binary cross entropy -- для задачи бинарной классификации
- Categorical cross entropy -- для задачи многоклассовой классификации

Все они реализованы в Keras и находятся в tf.keras.losses:

- tf.keras.losses.MSE()
- tf.keras.losses.binary_crossentropy()
- tf.keras.losses.sparse_categorical_crossentropy()

<br/>

**Определение оптимизатора**

- tf.keras.optimizers.Adam
- tf.keras.optimizers.SGD и многие другие.

Каждый из оптимизаторов имеет свои параметры, но все разделяют общий -- learning rate.

<br/>

### 3.9 Сохранение и загрузка моделей в TF

- [линк](https://colab.research.google.com/drive/130B8iGNIBi2mbWTqU7mEMVu1xUnov-jH)

<br/>

### 4.6 Свертки

<br/>

### 4.8 Демо. Сверточный слой в Keras

<br/>

### 4.11 Демо. Сверточная сеть в Keras

<br/>

### 4.12 Демо. Input pipeline

<br/>

### 5.2 Переобучение / аугментации

Аугментация искусственно делает датасет более разнообразным, а значит более сложным для "заучивания". Это очень эффективный метод борьбы с переобчуением, но у него конечно есть пределы, т.к. новых данных мы не добавляем.

- [линк](https://colab.research.google.com/drive/1_dqtypPH0Q5Gp0sSMqlvlsH23G91YJnp)

<br/>

### 5.4 Демо. Инференс моделей

<br/>

### 5.6 Что “видят” нейронные сети?

<br/>

### 5.8 Демо. Transfer learning в Keras

<br/>

### 6.5 Реализация слабой локализации с помощью скользящего окна

<br/>

### 6.8 Конвертация классификационной сети в полносвёрточную

<br/>

### 6.11 Реализация обучения FCN

<br/>

### 7.2 Реализация модернизированной FCN сети

<br/>

### 7.5 Реализация U-Net

<br/>

### 7.7 Реализация ASPP сети

<br/>

### 8.5 Реализация модели для Классификации+Локализации

<br/>

### 9.2 Подготовка обучающего датасета для R-CNN

<br/>

### 9.3 Создание и обучение модели

<br/>

### 9.4 Запуск R-CNN

<br/>

### 10

- Локализация объектов
- Детектирование объектов
- Сегментация объектов

### 10.2 Реализация Fast R-CNN

<br/>

### 10.6 Реализация SSD / YOLO

YOLO - You Only Look Once  
SSD - Single Shot Multibox Detector

<br/>

В Уроке 7 - Подключение google диска к colab.

В Уроке 8 - Fine Tuning, Transfer learning

В Уроке 9 - Сегментация объектов

<br/>

### 11.3 Демо. Генерация изображения как задача оптимизации

<br/>

### 11.4 Генерация изображения с перцептивным лоссом

<br/>

### 11.6 Демо. Генерация текстур в Keras

Style Transfer

<br/>

## 12. Генеративные состязательные сети (GAN)

### 12.4 Демо. 2D GAN

<br/>

### 12.7 Демо. Deep Convolutional GAN (DCGAN)

<br/>

## 13. NLP

<br/>

### 13.1 Цели и задачи NLP

<br/>

### 13.2 Предварительная обработка текста

<br/>

### 13.4 Векторизация текста: Bag of Words

<br/>

### 13.6 Векторизация слов: Word2Vec

<br/>

### 14.3 Реализация слоя RNN

<br/>

### 14.5 Реализация сети RNN

<br/>

### 14.8 Реализация LSTM. Часть 1

<br/>

### 14.15 Рекуррентные нейросети для классификации текстов

<br/>

### 14.16 Реализация и обучение классификатора текстов

<br/>

### 15.3 Реализация языковой модели

<br/>

### 15.5 Реализация Encoder-Decoder

Задачи машинного перевода

Архитектура "Трансформер" (отказ от рекуррентных сетей)

<br/>

## 16. Обучение с подкреплением (Reinforcement learning, RL)

<br/>

### 16.5 Знакомство с Gym

- [линк](https://colab.research.google.com/drive/1xFkpJg1a6jxs-I3znf-cpyquqI6HNm8p)

- [линк](https://colab.research.google.com/drive/1VeiscwJDIvJ1yUmo-fxcnYTBZn35pk8U)

<br/>

### 16.8 Q-функция

- [линк](https://colab.research.google.com/drive/1tJZwFv-cH6XLOzP_tJ-g4e5zoOeWpfu6)

<br/>

### 16.10 Реализация табличного Q-Learning

- [линк](https://colab.research.google.com/drive/1hqfEyGHKNIQ0M_vxMI3Hyfu8snm_j1Sl)

<br/>

### 17.2 Exploration

- [линк](https://colab.research.google.com/drive/1Ov9TbGwPt65od_BNgy5GF85Q8Ba3NX5Y)

<br/>

### 17.5 Реализация Deep Q-Network (DQN)

- [линк](https://colab.research.google.com/drive/15plRnuURCwSFT8p0132NfMe7a83MoENn)

<br/>

### 17.6 Experience Replay

<br/>

### 17.7 Policy Gradients

<br/>

## 18. Ускорение и оптимизация

### 18.4 Реализация поканальной сепарабельной свёртки

<br/>

### 18.5 Прореживание (Pruning)

<br/>

### 18.7 Применение TensorRT для оптимизации нейросетей

<br/>

## 19. Внедрение моделей в production

### Жизненный цикл ML проекта

### 19.3 Сохранение и загрузка моделей TensorFlow

- [Сохранение моделей TensorFlow](https://colab.research.google.com/drive/1oP6nZULQCN7Z6iM0lC8LKZbYIJUdaI4K)

- [Загрузка моделей TensorFlow](https://colab.research.google.com/drive/1ikKNW3Ja36GIw_5Uue08MW-IAYurDKyu)

### 19.4 TensorFlow Serving

- [линк](https://drive.google.com/drive/folders/1aOI96FXDnZnHmE-1YEjdsH_t1Xt1ntMh)
