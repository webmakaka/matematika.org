---
layout: page
title: TensorFlow Developer Certificate in 2021
description: Изучаем видеокурс TensorFlow Developer Certificate in 2021 от Zero to Mastery
keywords: Видеокурс, TensorFlow, английский язык, TensorFlow Developer Certificate in 2021, Zero to Mastery
permalink: /videos/ds/libs/tensorflow/en/tensorflow-developer-certificate-in-2021/
---

# [Udemy] [Andrei Neagoie, Daniel Bourke] TensorFlow Developer Certificate in 2021: Zero to Mastery [ENG, 2021]

<br/>

### [Daniel Bourke] Learn TensorFlow and Deep Learning fundamentals with Python (code-first introduction) [ENG, 2021]

<br/>

Первые 14 (из 37) часов можно бесплатно посмотреть в YouTube. Далее можно или купить, или найти.

<br/>

<div align="center">
    <iframe width="853" height="480" src="https://www.youtube.com/embed/videoseries?list=PL6vjgQ2-qJFfU2vF6-lG9DlSa4tROkzt9" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

<br/>

https://www.udemy.com/course/tensorflow-developer-certificate-machine-learning-zero-to-mastery/

<br/>

**GitHub:**  
https://github.com/mrdbourke/tensorflow-deep-learning


<br/>

В курсе ссылаются и рекомендуют книгу,
[Орельен Жерон, Прикладное машинное обучение с помощью Scikit-Learn, Keras и TensorFlow](/books/ds/ml/ru/hands-on-machine-learning-with-scikit-learn-and-tensorflow/)

<br/>

[00. Getting started with TensorFlow: A guide to the fundamentals](https://colab.research.google.com/github/mrdbourke/tensorflow-deep-learning/blob/main/00_tensorflow_fundamentals.ipynb)


[01. Neural Network Regression with TensorFlow](https://colab.research.google.com/github/mrdbourke/tensorflow-deep-learning/blob/main/01_neural_network_regression_in_tensorflow.ipynb)


<br/>


| **Hyperparameter** | **Typical value** |
| --- | --- |
| Input layer shape | Same shape as number of features (e.g. 3 for # bedrooms, # bathrooms, # car spaces in housing price prediction) |
| Hidden layer(s) | Problem specific, minimum = 1, maximum = unlimited |
| Neurons per hidden layer | Problem specific, generally 10 to 100 |
| Output layer shape | Same shape as desired prediction shape (e.g. 1 for house price) |
| Hidden activation | Usually [ReLU](https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning) (rectified linear unit) |
| Output activation | None, ReLU, logistic/tanh |
| Loss function | [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) (mean square error) or [MAE](https://en.wikipedia.org/wiki/Mean_absolute_error) (mean absolute error)/Huber (combination of MAE/MSE) if outliers |
| Optimizer | [SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) (stochastic gradient descent), [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) |
