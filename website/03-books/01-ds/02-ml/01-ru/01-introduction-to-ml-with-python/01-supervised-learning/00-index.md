---
layout: page
title: Машинное обучения с учителем (supervised learning)
description: Машинное обучения с учителем (supervised learning)
keywords: Машинное обучения с учителем, supervised learning
permalink: /books/ds/ml/ru/scikit-learn/introduction-to-ml-with-python/supervised-learning/
---

# Машинное обучения с учителем (supervised learning)

https://github.com/amueller/introduction_to_ml_with_python/blob/master/02-supervised-learning.ipynb

Обучение с учителем используется всякий раз, когда мы хотим предсказать определенный результат (ответ) по данному объекту, и у нас есть пары объект-ответ. Мы строим модель машинного обучения на основе этих пар объект-ответ, которые составляют наш обучающий набор данных. Наша цель состоит в том, чтобы получить точные прогнозы для новых, никогда ранее не встречавшихся данных. Машинное обучение с учителем часто требует вмешательства человека, чтобы получить обучающий набор данных, но потом оно автоматизирует и часто ускоряет решение трудоемких или неосуществимых задач.

Есть две основные задачи машинного обучения с учителем:

- классификация (classification)
- регрессия (regression)

<br/>

Переобучение (overfitting) - модель слишком точно подстраивается под особенности обучающего набора. В результате чего, хорошо работает на обучающем наборе, но не умеет обобщать результат на новые данные.

Недообучение (underfitting) - недостаточный охват многообразия и изменчивости данных. Модель плохо работает даже на обучающем наборе.

Регуляризация (regularization) - явное ограничение модели для предотвращения переобучения.

<br/>

### Алгоритмы машинного обучения с учителем:

- <a href="/books/ds/ml/ru/scikit-learn/introduction-to-ml-with-python/supervised-learning/k-nearest-neighbors/">Ближайшие соседи (k-Nearest Neighbors)</a> - Подходит для небольших наборов данных, хорош в качестве базовой модели, прост в объяснении.
- <a href="/books/ds/ml/ru/scikit-learn/introduction-to-ml-with-python/supervised-learning/linear-models/">Линейные модели (Linear Models)</a> - Считается первым алгоритмом, который нужно попробовать, хорош для очень больших наборов данных, подходит для данных с очень высокой размерностью.
- <a href="/books/ds/ml/ru/scikit-learn/introduction-to-ml-with-python/supervised-learning/naive-bayes-classifiers/">Наивный байесовский классификатор (Naive Bayes Classifiers)</a> - Подходит только для классификации. Работает даже быстрее, чем линейные модели, хорош для очень больших наборов данных и высокоразмерных данных. Часто менее точен, чем линейные модели.
- Деревья решений (Decision trees)- Очень быстрый метод, не нужно масштабировать данные, результаты можно визуализировать и легко объяснить.
- Случайные леса (Random forests) - Почти всегда работают лучше, чем одно дерево решений, очень устойчивый и мощный метод. Не нужно масштабировать данные.
  Плохо работает с данными очень высокой размерности и разреженными данными.
- Градиентный бустинг деревьев решений (Gradient Boosted Regression Trees (Gradient Boosting Machines)) - Как правило, немного более точен, чем случайный лес. В отличие от случайного леса медленнее обучается, но быстрее предсказывает и требует меньше памяти. По сравнению со случайным лесом требует настройки большего числа параметров.
- Машины опорных векторов (Kernelized Support Vector Machines, SVM) - Мощный метод для работы с наборами данных среднего размера и признаками, измеренными в едином масштабе.
  Требует масштабирования данных, чувствителен к изменению параметров.
- Нейронные сети (Neural Networks (Deep Learning)) - Можно построить очень сложные модели, особенно для больших наборов данных. Чувствительны к масштабированию данных и выбору параметров. Большим моделям требуется много времени для обучения.
